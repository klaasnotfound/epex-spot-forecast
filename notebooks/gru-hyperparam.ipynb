{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d344ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather and spot market data from the DB\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "data_start = \"2023-01-01\"\n",
    "data_end = \"2025-07-01\"\n",
    "\n",
    "db_filepath = \"data/db/local.db\"\n",
    "con = duckdb.connect(db_filepath)\n",
    "weather_cols = [\n",
    "    \"temperature_2m_degc\",\n",
    "    \"shortwave_radiation_wm2\",\n",
    "    \"direct_radiation_wm2\",\n",
    "    \"diffuse_radiation_wm2\",\n",
    "    \"direct_normal_irradiance_wm2\",\n",
    "    \"global_tilted_irradiance_wm2\",\n",
    "    \"terrestrial_radiation_wm2\",\n",
    "    \"wind_speed_10m_kmh\",\n",
    "    \"wind_speed_80m_kmh\",\n",
    "    \"wind_speed_120m_kmh\",\n",
    "    \"cloud_cover_perc\",\n",
    "    \"cloud_cover_low_perc\",\n",
    "    \"cloud_cover_mid_perc\",\n",
    "    \"cloud_cover_high_perc\",\n",
    "    \"visibility_m\",\n",
    "]\n",
    "w_cols = \", \".join([f\"open_meteo_agg_hourly.{col}\" for col in weather_cols])\n",
    "market_cols = [\n",
    "    \"non_ren_prod_kw\",\n",
    "    \"ren_prod_kw\",\n",
    "    \"load_kw\",\n",
    "    \"daa_price_eurmwh\",\n",
    "    \"idc_av_price_eurmwh\",\n",
    "    \"idc_low_price_eurmwh\",\n",
    "    \"idc_high_price_eurmwh\",\n",
    "]\n",
    "m_cols = \", \".join([f\"epex_market.{col}\" for col in market_cols])\n",
    "\n",
    "data = con.sql(f\"\"\"\n",
    "              SELECT open_meteo_agg_hourly.ts,\n",
    "                     extract('month' FROM open_meteo_agg_hourly.ts) - 1 as month,\n",
    "                     extract('day' FROM open_meteo_agg_hourly.ts) - 1 as day,\n",
    "                     extract('dow' FROM open_meteo_agg_hourly.ts) as dow,\n",
    "                     extract('hour' FROM open_meteo_agg_hourly.ts) as hour,\n",
    "                     {w_cols}, {m_cols}\n",
    "              FROM open_meteo_agg_hourly\n",
    "              JOIN epex_market ON open_meteo_agg_hourly.ts = epex_market.ts\n",
    "              WHERE open_meteo_agg_hourly.ts >= '{data_start}'\n",
    "                AND open_meteo_agg_hourly.ts < '{data_end}'\n",
    "              ORDER BY open_meteo_agg_hourly.ts\n",
    "              \"\"\").df()\n",
    "data.index = pd.Index(data[\"ts\"])\n",
    "data = data.drop(\"ts\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "392256dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data and create sets / loaders\n",
    "\n",
    "# Copy the original\n",
    "tdata = data.copy()\n",
    "\n",
    "# We can only use EPEX values from the previous day\n",
    "last_weather_col_idx = tdata.columns.tolist().index(weather_cols[-1])\n",
    "first_weather_col_idx = tdata.columns.tolist().index(weather_cols[0])\n",
    "today_cols = tdata.columns[0:last_weather_col_idx]\n",
    "tdata[today_cols] = tdata[today_cols].shift(-24)\n",
    "tdata = tdata[:-24]\n",
    "\n",
    "# Fill N/A values\n",
    "na_columns = tdata.columns[tdata.isna().any()].tolist()\n",
    "for col in na_columns:\n",
    "    tdata[col] = tdata[col].fillna(tdata[col].mean())\n",
    "\n",
    "# Fill in missing daylight-saving hours\n",
    "for idx in range(1, tdata.shape[0]):\n",
    "    ts = tdata.index[idx]\n",
    "    prev_ts = tdata.index[idx - 1]\n",
    "    diff = (ts.hour - prev_ts.hour) % 24\n",
    "    if diff != 1:\n",
    "        iso_str = f\"{ts.year}-{ts.month:02d}-{ts.day:02d}T{(ts.hour - 1):02d}:00:00\"\n",
    "        new_ts = pd.to_datetime(iso_str)\n",
    "        tdata = pd.concat(\n",
    "            [\n",
    "                tdata,\n",
    "                pd.DataFrame(tdata.loc[prev_ts].to_dict(), index=[new_ts]),\n",
    "            ]\n",
    "        )\n",
    "tdata.sort_index(ascending=True, inplace=True)\n",
    "tdata[\"hour\"] = tdata.hour\n",
    "\n",
    "# Note down the price amplitude before normalizing\n",
    "price_mean = tdata[\"idc_av_price_eurmwh\"].mean()\n",
    "price_std = tdata[\"idc_av_price_eurmwh\"].std()\n",
    "\n",
    "# Normalize with min/max for the fixed date columns, mean for the rest\n",
    "for c in tdata.columns[1:first_weather_col_idx]:\n",
    "    tdata[c] = (tdata[c] - tdata[c].min()) / (tdata[c].max() - tdata[c].min())\n",
    "tdata[tdata.columns[first_weather_col_idx:]] = (\n",
    "    tdata[tdata.columns[first_weather_col_idx:]]\n",
    "    - tdata[tdata.columns[first_weather_col_idx:]].mean()\n",
    ") / tdata[tdata.columns[first_weather_col_idx:]].std()\n",
    "\n",
    "# Create training and test rows\n",
    "split_idx = int((0.8 * len(tdata)) // 24 * 24)\n",
    "iso_str = f\"{tdata.index[split_idx]}\"[:10]\n",
    "cutoff_date = pd.to_datetime(iso_str)\n",
    "train_data = tdata.loc[(tdata.index < cutoff_date)]\n",
    "test_data = tdata.loc[(tdata.index >= cutoff_date)]\n",
    "# train_data = train_data.drop(\"daa_price_eurmwh\", axis=1)\n",
    "# test_data = test_data.drop(\"daa_price_eurmwh\", axis=1)\n",
    "train_rows = train_data.values.astype(\"float32\")\n",
    "test_rows = test_data.values.astype(\"float32\")\n",
    "price_idx = train_data.columns.tolist().index(\"idc_av_price_eurmwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a8919c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "\n",
    "from numpy import ndarray\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Datasets are created from sliding windows\n",
    "def create_dataset(\n",
    "    data: ndarray, lookback_hours: int, predict_hours: int\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    X, y = [], []\n",
    "    for i in range(lookback_hours, len(data) - predict_hours, 24):\n",
    "        feature = data[i - lookback_hours : i]\n",
    "        target = data[i : i + predict_hours][:, price_idx]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "\n",
    "# Create the sets\n",
    "lookback_hours = 1 * 24\n",
    "predict_hours = 1 * 24\n",
    "X_train, y_train = create_dataset(train_rows, lookback_hours, predict_hours)\n",
    "X_test, y_test = create_dataset(test_rows, lookback_hours, predict_hours)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe71d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size: int, num_layers=2, hidden_size=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.Linear(hidden_size // 2, 8),\n",
    "            nn.Linear(8, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ffc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Layers\tHidden Size\t# Params\tBlend Factor\tVal. Loss\tØ Diff DAA (EUR)\tσ Diff DAA (EUR)\tØ Diff Pred. (EUR)\tσ Diff Pred. (EUR)\tØ Diff Blended (EUR)\tσ Diff Blended (EUR)\n",
      "4\t64\t94897\t0.2\t0.2329\t12.781\t33.986\t20.927\t20.498\t12.114\t13.436\n",
      "4\t64\t94897\t0.2\t0.2364\t12.781\t33.986\t21.779\t20.570\t12.271\t13.371\n",
      "4\t64\t94897\t0.2\t0.2368\t12.781\t33.986\t21.009\t20.708\t11.967\t13.549\n",
      "4\t64\t94897\t0.2\t0.2388\t12.781\t33.986\t20.677\t21.244\t11.830\t13.277\n",
      "4\t64\t94897\t0.2\t0.2436\t12.781\t33.986\t21.218\t20.629\t11.869\t13.331\n",
      "4\t96\t208385\t0.2\t0.2388\t12.781\t33.986\t21.479\t21.386\t12.012\t13.392\n",
      "4\t96\t208385\t0.2\t0.2380\t12.781\t33.986\t20.937\t20.355\t12.005\t13.374\n",
      "4\t96\t208385\t0.2\t0.2411\t12.781\t33.986\t21.159\t21.002\t12.125\t13.342\n",
      "4\t96\t208385\t0.2\t0.2386\t12.781\t33.986\t21.088\t20.990\t12.003\t13.604\n",
      "4\t96\t208385\t0.2\t0.2351\t12.781\t33.986\t20.809\t20.493\t11.950\t13.326\n",
      "4\t128\t365905\t0.2\t0.2387\t12.781\t33.986\t20.946\t20.167\t12.084\t13.503\n",
      "4\t128\t365905\t0.2\t0.2328\t12.781\t33.986\t20.666\t20.744\t11.984\t13.466\n",
      "4\t128\t365905\t0.2\t0.2337\t12.781\t33.986\t20.463\t20.612\t11.867\t13.379\n",
      "4\t128\t365905\t0.2\t0.2412\t12.781\t33.986\t20.672\t20.392\t12.089\t13.465\n",
      "4\t128\t365905\t0.2\t0.2344\t12.781\t33.986\t20.707\t20.346\t12.032\t13.528\n",
      "4\t192\t813041\t0.2\t0.2317\t12.781\t33.986\t20.919\t20.906\t12.056\t13.483\n",
      "4\t192\t813041\t0.2\t0.2374\t12.781\t33.986\t21.276\t20.713\t12.060\t13.344\n",
      "4\t192\t813041\t0.2\t0.2289\t12.781\t33.986\t20.070\t20.313\t11.956\t13.319\n",
      "4\t192\t813041\t0.2\t0.2359\t12.781\t33.986\t21.126\t20.156\t12.194\t13.460\n",
      "4\t192\t813041\t0.2\t0.2309\t12.781\t33.986\t20.621\t20.568\t11.914\t13.575\n",
      "4\t256\t1436305\t0.2\t0.2281\t12.781\t33.986\t20.311\t20.465\t11.918\t13.360\n",
      "4\t256\t1436305\t0.2\t0.2367\t12.781\t33.986\t20.995\t20.721\t12.052\t13.478\n",
      "4\t256\t1436305\t0.2\t0.2426\t12.781\t33.986\t20.649\t20.846\t11.995\t13.670\n",
      "4\t256\t1436305\t0.2\t0.2329\t12.781\t33.986\t20.376\t20.660\t12.042\t13.481\n",
      "4\t256\t1436305\t0.2\t0.2328\t12.781\t33.986\t21.287\t20.371\t11.977\t13.477\n",
      "4\t384\t3211217\t0.2\t0.2343\t12.781\t33.986\t20.851\t20.303\t12.003\t13.240\n",
      "4\t384\t3211217\t0.2\t0.2304\t12.781\t33.986\t20.798\t20.429\t12.056\t13.271\n",
      "4\t384\t3211217\t0.2\t0.2407\t12.781\t33.986\t21.193\t20.044\t12.235\t13.522\n",
      "4\t384\t3211217\t0.2\t0.2262\t12.781\t33.986\t20.803\t20.595\t11.999\t13.325\n",
      "4\t384\t3211217\t0.2\t0.2278\t12.781\t33.986\t20.362\t20.353\t12.020\t13.353\n"
     ]
    }
   ],
   "source": [
    "# Iterate hyperparams, train and evaluate the model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "max_epochs = 200\n",
    "patience = 10\n",
    "blend_fac = 0.2\n",
    "\n",
    "# Print the header\n",
    "print(\n",
    "    \"# Layers\\tHidden Size\\t# Params\\tBlend Factor\\tVal. Loss\\tØ Diff DAA (EUR)\\tσ Diff DAA (EUR)\\tØ Diff Pred. (EUR)\\tσ Diff Pred. (EUR)\\tØ Diff Blended (EUR)\\tσ Diff Blended (EUR)\"\n",
    ")\n",
    "\n",
    "for hidden_size in [64, 96, 128, 192, 256, 384]:\n",
    "    for num_layers in [4]:\n",
    "        for run in range(5):\n",
    "            # Create the model\n",
    "            loss_fn = nn.MSELoss()\n",
    "            model = GRUModel(X_train.shape[2], num_layers, hidden_size).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=0.5, patience=5\n",
    "            )\n",
    "            trainable_params = sum(\n",
    "                p.numel() for p in model.parameters() if p.requires_grad\n",
    "            )\n",
    "\n",
    "            # Train the model until there's no more improvement\n",
    "            best_val_loss = float(\"inf\")\n",
    "            best_weights = None\n",
    "            patience_counter = 0\n",
    "            for epoch in range(max_epochs):\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                for X_batch, y_batch in train_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(X_batch)\n",
    "                    loss = loss_fn(output, torch.unsqueeze(y_batch, 2))\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, y_batch in test_loader:\n",
    "                        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                        output = model(torch.squeeze(X_batch))\n",
    "                        val_loss += loss_fn(output, torch.unsqueeze(y_batch, 2)).item()\n",
    "                val_loss /= len(test_loader)\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "                # Stop early if there's no more improvement\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_weights = model.state_dict()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        break\n",
    "\n",
    "            # Evaluate the price difference\n",
    "            with torch.no_grad():\n",
    "                model.cpu()\n",
    "                # Get the predicted data\n",
    "                y_pred_test = model(X_test).clone().detach().cpu().numpy()\n",
    "                y_pred_test = y_pred_test.reshape(\n",
    "                    y_pred_test.shape[0] * y_pred_test.shape[1]\n",
    "                )\n",
    "                test_plot = np.ones_like(tdata[\"idc_av_price_eurmwh\"]) * np.nan\n",
    "                test_plot[\n",
    "                    len(train_rows) + lookback_hours : len(train_rows)\n",
    "                    + lookback_hours\n",
    "                    + y_pred_test.shape[0]\n",
    "                ] = y_pred_test\n",
    "\n",
    "                # Transform it back\n",
    "                real_price = (\n",
    "                    tdata[\"idc_av_price_eurmwh\"].to_numpy() * price_std + price_mean\n",
    "                )\n",
    "                daa_price = (\n",
    "                    tdata[\"daa_price_eurmwh\"].to_numpy() * price_std + price_mean\n",
    "                )\n",
    "                pred_test_price = test_plot * price_std + price_mean\n",
    "\n",
    "                # Calculate the blended price\n",
    "                blend_price = (1 - blend_fac) * daa_price + blend_fac * pred_test_price\n",
    "\n",
    "                # Calculate the absolute diff meand and stddev\n",
    "                pdata = pd.DataFrame({\"intraday_price\": real_price}, index=tdata.index)\n",
    "                daa_diff = pdata[\"intraday_price\"] - daa_price\n",
    "                daa_adm = daa_diff.abs().mean()\n",
    "                daa_ads = daa_diff.abs().std()\n",
    "                pred_diff = pdata[\"intraday_price\"] - pred_test_price\n",
    "                pred_adm = pred_diff.abs().mean()\n",
    "                pred_ads = pred_diff.abs().std()\n",
    "                blend_diff = pdata[\"intraday_price\"] - blend_price\n",
    "                blend_adm = blend_diff.abs().mean()\n",
    "                blend_ads = blend_diff.abs().std()\n",
    "\n",
    "                # Print the result\n",
    "                print(\n",
    "                    f\"{num_layers}\\t{hidden_size}\\t{trainable_params}\\t{blend_fac}\\t{best_val_loss:.4f}\\t{daa_adm:.3f}\\t{daa_ads:.3f}\\t{pred_adm:.3f}\\t{pred_ads:.3f}\\t{blend_adm:.3f}\\t{blend_ads:.3f}\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
