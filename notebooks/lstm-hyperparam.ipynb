{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41d344ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather and spot market data from the DB\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "data_start = \"2023-01-01\"\n",
    "data_end = \"2025-07-01\"\n",
    "\n",
    "db_filepath = \"data/db/local.db\"\n",
    "con = duckdb.connect(db_filepath)\n",
    "weather_cols = [\n",
    "    \"temperature_2m_degc\",\n",
    "    \"shortwave_radiation_wm2\",\n",
    "    \"direct_radiation_wm2\",\n",
    "    \"diffuse_radiation_wm2\",\n",
    "    \"direct_normal_irradiance_wm2\",\n",
    "    \"global_tilted_irradiance_wm2\",\n",
    "    \"terrestrial_radiation_wm2\",\n",
    "    \"wind_speed_10m_kmh\",\n",
    "    \"wind_speed_80m_kmh\",\n",
    "    \"wind_speed_120m_kmh\",\n",
    "    \"cloud_cover_perc\",\n",
    "    \"cloud_cover_low_perc\",\n",
    "    \"cloud_cover_mid_perc\",\n",
    "    \"cloud_cover_high_perc\",\n",
    "    \"visibility_m\",\n",
    "]\n",
    "w_cols = \", \".join([f\"open_meteo_agg_hourly.{col}\" for col in weather_cols])\n",
    "market_cols = [\n",
    "    \"non_ren_prod_kw\",\n",
    "    \"ren_prod_kw\",\n",
    "    \"load_kw\",\n",
    "    \"daa_price_eurmwh\",\n",
    "    \"idc_av_price_eurmwh\",\n",
    "    \"idc_low_price_eurmwh\",\n",
    "    \"idc_high_price_eurmwh\",\n",
    "]\n",
    "m_cols = \", \".join([f\"epex_market.{col}\" for col in market_cols])\n",
    "\n",
    "data = con.sql(f\"\"\"\n",
    "              SELECT open_meteo_agg_hourly.ts,\n",
    "                     extract('month' FROM open_meteo_agg_hourly.ts) - 1 as month,\n",
    "                     extract('day' FROM open_meteo_agg_hourly.ts) - 1 as day,\n",
    "                     extract('dow' FROM open_meteo_agg_hourly.ts) as dow,\n",
    "                     extract('hour' FROM open_meteo_agg_hourly.ts) as hour,\n",
    "                     {w_cols}, {m_cols}\n",
    "              FROM open_meteo_agg_hourly\n",
    "              JOIN epex_market ON open_meteo_agg_hourly.ts = epex_market.ts\n",
    "              WHERE open_meteo_agg_hourly.ts >= '{data_start}'\n",
    "                AND open_meteo_agg_hourly.ts < '{data_end}'\n",
    "              ORDER BY open_meteo_agg_hourly.ts\n",
    "              \"\"\").df()\n",
    "data.index = pd.Index(data[\"ts\"])\n",
    "data = data.drop(\"ts\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "392256dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data and create sets / loaders\n",
    "\n",
    "# Copy the original\n",
    "tdata = data.copy()\n",
    "\n",
    "# We can only use EPEX values from the previous day\n",
    "last_weather_col_idx = tdata.columns.tolist().index(weather_cols[-1])\n",
    "first_weather_col_idx = tdata.columns.tolist().index(weather_cols[0])\n",
    "today_cols = tdata.columns[0:last_weather_col_idx]\n",
    "tdata[today_cols] = tdata[today_cols].shift(-24)\n",
    "tdata = tdata[:-24]\n",
    "\n",
    "# Fill N/A values\n",
    "na_columns = tdata.columns[tdata.isna().any()].tolist()\n",
    "for col in na_columns:\n",
    "    tdata[col] = tdata[col].fillna(tdata[col].mean())\n",
    "\n",
    "# Fill in missing daylight-saving hours\n",
    "for idx in range(1, tdata.shape[0]):\n",
    "    ts = tdata.index[idx]\n",
    "    prev_ts = tdata.index[idx - 1]\n",
    "    diff = (ts.hour - prev_ts.hour) % 24\n",
    "    if diff != 1:\n",
    "        iso_str = f\"{ts.year}-{ts.month:02d}-{ts.day:02d}T{(ts.hour - 1):02d}:00:00\"\n",
    "        new_ts = pd.to_datetime(iso_str)\n",
    "        tdata = pd.concat(\n",
    "            [\n",
    "                tdata,\n",
    "                pd.DataFrame(tdata.loc[prev_ts].to_dict(), index=[new_ts]),\n",
    "            ]\n",
    "        )\n",
    "tdata.sort_index(ascending=True, inplace=True)\n",
    "tdata[\"hour\"] = tdata.hour\n",
    "\n",
    "# Note down the price amplitude before normalizing\n",
    "price_mean = tdata[\"idc_av_price_eurmwh\"].mean()\n",
    "price_std = tdata[\"idc_av_price_eurmwh\"].std()\n",
    "\n",
    "# Normalize with min/max for the fixed date columns, mean for the rest\n",
    "for c in tdata.columns[1:first_weather_col_idx]:\n",
    "    tdata[c] = (tdata[c] - tdata[c].min()) / (tdata[c].max() - tdata[c].min())\n",
    "tdata[tdata.columns[first_weather_col_idx:]] = (\n",
    "    tdata[tdata.columns[first_weather_col_idx:]]\n",
    "    - tdata[tdata.columns[first_weather_col_idx:]].mean()\n",
    ") / tdata[tdata.columns[first_weather_col_idx:]].std()\n",
    "\n",
    "# Create training and test rows\n",
    "split_idx = int((0.8 * len(tdata)) // 24 * 24)\n",
    "iso_str = f\"{tdata.index[split_idx]}\"[:10]\n",
    "cutoff_date = pd.to_datetime(iso_str)\n",
    "train_data = tdata.loc[(tdata.index < cutoff_date)]\n",
    "test_data = tdata.loc[(tdata.index >= cutoff_date)]\n",
    "# train_data = train_data.drop(\"daa_price_eurmwh\", axis=1)\n",
    "# test_data = test_data.drop(\"daa_price_eurmwh\", axis=1)\n",
    "train_rows = train_data.values.astype(\"float32\")\n",
    "test_rows = test_data.values.astype(\"float32\")\n",
    "price_idx = train_data.columns.tolist().index(\"idc_av_price_eurmwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a8919c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and loaders\n",
    "\n",
    "from numpy import ndarray\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# Datasets are created from sliding windows\n",
    "def create_dataset(\n",
    "    data: ndarray, lookback_hours: int, predict_hours: int\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    X, y = [], []\n",
    "    for i in range(lookback_hours, len(data) - predict_hours, 24):\n",
    "        feature = data[i - lookback_hours : i]\n",
    "        target = data[i : i + predict_hours][:, price_idx]\n",
    "        X.append(feature)\n",
    "        y.append(target)\n",
    "    return torch.tensor(X), torch.tensor(y)\n",
    "\n",
    "\n",
    "# Create the sets\n",
    "lookback_hours = 1 * 24\n",
    "predict_hours = 1 * 24\n",
    "X_train, y_train = create_dataset(train_rows, lookback_hours, predict_hours)\n",
    "X_test, y_test = create_dataset(test_rows, lookback_hours, predict_hours)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe71d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model\n",
    "\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size: int, num_layers=2, hidden_size=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.Linear(hidden_size // 2, 8),\n",
    "            nn.Linear(8, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ffc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Layers\tHidden Size\t# Params\tBlend Factor\tVal. Loss\tØ Diff DAA (EUR)\tσ Diff DAA (EUR)\tØ Diff Pred. (EUR)\tσ Diff Pred. (EUR)\tØ Diff Blended (EUR)\tσ Diff Blended (EUR)\n",
      "4\t64\t125745\t0.2\t0.2294\t12.781\t33.986\t21.683\t21.538\t12.251\t13.617\n",
      "4\t64\t125745\t0.2\t0.2406\t12.781\t33.986\t21.320\t21.220\t11.971\t13.671\n",
      "4\t64\t125745\t0.2\t0.2291\t12.781\t33.986\t20.960\t20.585\t12.026\t13.531\n",
      "4\t64\t125745\t0.2\t0.2340\t12.781\t33.986\t20.621\t20.139\t11.979\t13.472\n",
      "4\t64\t125745\t0.2\t0.2402\t12.781\t33.986\t22.454\t22.705\t12.264\t13.779\n",
      "4\t96\t276161\t0.2\t0.2383\t12.781\t33.986\t21.122\t21.137\t11.973\t13.580\n",
      "4\t96\t276161\t0.2\t0.2416\t12.781\t33.986\t20.663\t20.476\t12.115\t13.484\n",
      "4\t96\t276161\t0.2\t0.2291\t12.781\t33.986\t21.513\t20.116\t12.256\t13.736\n",
      "4\t96\t276161\t0.2\t0.2457\t12.781\t33.986\t24.330\t22.499\t12.565\t13.641\n",
      "4\t96\t276161\t0.2\t0.2294\t12.781\t33.986\t21.151\t20.285\t12.119\t13.431\n",
      "4\t128\t484945\t0.2\t0.2299\t12.781\t33.986\t19.996\t20.480\t12.032\t13.591\n",
      "4\t128\t484945\t0.2\t0.2392\t12.781\t33.986\t20.874\t21.000\t12.131\t13.524\n",
      "4\t128\t484945\t0.2\t0.2220\t12.781\t33.986\t20.678\t20.112\t12.071\t13.570\n",
      "4\t128\t484945\t0.2\t0.2212\t12.781\t33.986\t21.175\t21.489\t12.168\t13.545\n",
      "4\t128\t484945\t0.2\t0.2527\t12.781\t33.986\t22.778\t21.788\t12.289\t13.618\n",
      "4\t192\t1077617\t0.2\t0.2274\t12.781\t33.986\t20.378\t20.351\t11.947\t13.483\n",
      "4\t192\t1077617\t0.2\t0.2335\t12.781\t33.986\t21.619\t20.505\t12.097\t13.664\n",
      "4\t192\t1077617\t0.2\t0.2262\t12.781\t33.986\t20.325\t21.443\t11.971\t13.454\n",
      "4\t192\t1077617\t0.2\t0.2329\t12.781\t33.986\t21.106\t20.559\t12.017\t13.366\n",
      "4\t192\t1077617\t0.2\t0.2267\t12.781\t33.986\t21.957\t20.627\t12.209\t13.625\n",
      "4\t256\t1903761\t0.2\t0.2387\t12.781\t33.986\t21.527\t21.492\t12.251\t13.587\n",
      "4\t256\t1903761\t0.2\t0.2093\t12.781\t33.986\t19.604\t19.362\t12.028\t13.370\n",
      "4\t256\t1903761\t0.2\t0.2430\t12.781\t33.986\t20.806\t20.925\t11.985\t13.631\n",
      "4\t256\t1903761\t0.2\t0.2396\t12.781\t33.986\t20.979\t21.043\t12.134\t13.513\n",
      "4\t256\t1903761\t0.2\t0.2397\t12.781\t33.986\t22.542\t21.186\t12.535\t13.556\n",
      "4\t384\t4256465\t0.2\t0.2219\t12.781\t33.986\t20.172\t20.229\t11.821\t13.526\n",
      "4\t384\t4256465\t0.2\t0.2307\t12.781\t33.986\t21.008\t20.040\t12.110\t13.541\n",
      "4\t384\t4256465\t0.2\t0.2262\t12.781\t33.986\t20.670\t19.894\t12.057\t13.637\n",
      "4\t384\t4256465\t0.2\t0.2216\t12.781\t33.986\t20.133\t19.893\t11.917\t13.495\n",
      "4\t384\t4256465\t0.2\t0.2365\t12.781\t33.986\t21.073\t21.380\t11.971\t13.589\n"
     ]
    }
   ],
   "source": [
    "# Iterate hyperparams, train and evaluate the model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "max_epochs = 200\n",
    "patience = 10\n",
    "blend_fac = 0.2\n",
    "\n",
    "# Print the header\n",
    "print(\n",
    "    \"# Layers\\tHidden Size\\t# Params\\tBlend Factor\\tVal. Loss\\tØ Diff DAA (EUR)\\tσ Diff DAA (EUR)\\tØ Diff Pred. (EUR)\\tσ Diff Pred. (EUR)\\tØ Diff Blended (EUR)\\tσ Diff Blended (EUR)\"\n",
    ")\n",
    "\n",
    "for hidden_size in [64, 96, 128, 192, 256, 384]:\n",
    "    for num_layers in [4]:\n",
    "        for run in range(5):\n",
    "            # Create the model\n",
    "            loss_fn = nn.MSELoss()\n",
    "            model = LSTMModel(X_train.shape[2], num_layers, hidden_size).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"min\", factor=0.5, patience=5\n",
    "            )\n",
    "            trainable_params = sum(\n",
    "                p.numel() for p in model.parameters() if p.requires_grad\n",
    "            )\n",
    "\n",
    "            # Train the model until there's no more improvement\n",
    "            best_val_loss = float(\"inf\")\n",
    "            best_weights = None\n",
    "            patience_counter = 0\n",
    "            for epoch in range(max_epochs):\n",
    "                model.train()\n",
    "                train_loss = 0\n",
    "                for X_batch, y_batch in train_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(X_batch)\n",
    "                    loss = loss_fn(output, torch.unsqueeze(y_batch, 2))\n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    optimizer.step()\n",
    "                    train_loss += loss.item()\n",
    "                train_loss /= len(train_loader)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for X_batch, y_batch in test_loader:\n",
    "                        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                        output = model(torch.squeeze(X_batch))\n",
    "                        val_loss += loss_fn(output, torch.unsqueeze(y_batch, 2)).item()\n",
    "                val_loss /= len(test_loader)\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "                # Stop early if there's no more improvement\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_weights = model.state_dict()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        break\n",
    "\n",
    "            # Evaluate the price difference\n",
    "            with torch.no_grad():\n",
    "                model.cpu()\n",
    "                # Get the predicted data\n",
    "                y_pred_test = model(X_test).clone().detach().cpu().numpy()\n",
    "                y_pred_test = y_pred_test.reshape(\n",
    "                    y_pred_test.shape[0] * y_pred_test.shape[1]\n",
    "                )\n",
    "                test_plot = np.ones_like(tdata[\"idc_av_price_eurmwh\"]) * np.nan\n",
    "                test_plot[\n",
    "                    len(train_rows) + lookback_hours : len(train_rows)\n",
    "                    + lookback_hours\n",
    "                    + y_pred_test.shape[0]\n",
    "                ] = y_pred_test\n",
    "\n",
    "                # Transform it back\n",
    "                real_price = (\n",
    "                    tdata[\"idc_av_price_eurmwh\"].to_numpy() * price_std + price_mean\n",
    "                )\n",
    "                daa_price = (\n",
    "                    tdata[\"daa_price_eurmwh\"].to_numpy() * price_std + price_mean\n",
    "                )\n",
    "                pred_test_price = test_plot * price_std + price_mean\n",
    "\n",
    "                # Calculate the blended price\n",
    "                blend_price = (1 - blend_fac) * daa_price + blend_fac * pred_test_price\n",
    "\n",
    "                # Calculate the absolute diff meand and stddev\n",
    "                pdata = pd.DataFrame({\"intraday_price\": real_price}, index=tdata.index)\n",
    "                daa_diff = pdata[\"intraday_price\"] - daa_price\n",
    "                daa_adm = daa_diff.abs().mean()\n",
    "                daa_ads = daa_diff.abs().std()\n",
    "                pred_diff = pdata[\"intraday_price\"] - pred_test_price\n",
    "                pred_adm = pred_diff.abs().mean()\n",
    "                pred_ads = pred_diff.abs().std()\n",
    "                blend_diff = pdata[\"intraday_price\"] - blend_price\n",
    "                blend_adm = blend_diff.abs().mean()\n",
    "                blend_ads = blend_diff.abs().std()\n",
    "\n",
    "                # Print the result\n",
    "                print(\n",
    "                    f\"{num_layers}\\t{hidden_size}\\t{trainable_params}\\t{blend_fac}\\t{best_val_loss:.4f}\\t{daa_adm:.3f}\\t{daa_ads:.3f}\\t{pred_adm:.3f}\\t{pred_ads:.3f}\\t{blend_adm:.3f}\\t{blend_ads:.3f}\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
